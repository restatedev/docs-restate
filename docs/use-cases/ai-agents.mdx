---
title: "AI Agents"
description: "Build resilient, observable AI agents that recover from failures and handle complex multi-step tasks."
icon: "robot"
---

## Why Restate for AI Agents?

AI agents are long-running processes that combine LLMs with tools and external APIs to complete complex tasks. Traditional implementations struggle with failures, losing progress when API calls fail or services crash. Restate solves these challenges by making agents **resilient to failures**, **stateful across conversations**, and **observable** without managing complex retry logic or external state stores.

### Resilient Agent Execution

AI agents make multiple LLM calls and tool executions that can fail due to rate limits, network issues, or service outages. Restate uses Durable Execution to make your agents withstand failures without losing progress.

The Restate SDK records the steps the agent executes in a log and replays them if the process crashes or is restarted.

**Automatic Recovery Features:**
- **LLM call persistence**: Every model response is saved and replayed during recovery using `durableCalls` middleware
- **Tool execution durability**: External API calls are retried until they succeed with `ctx.run`
- **State consistency**: Agent state remains consistent across failures and restarts

### Simple Integration with AI SDKs

Restate works seamlessly with popular AI frameworks like Vercel AI SDK and OpenAI Agent SDK. No need to rewrite your existing agent logic:
```typescript
export default restate.service({
  name: "WeatherAgent",
  handlers: {
    run: async (ctx: restate.Context, { prompt }: { prompt: string }) => {
      const model = wrapLanguageModel({
        model: openai("gpt-4o"),
        middleware: durableCalls(ctx, { maxRetryAttempts: 3 }),
      });

      const { text } = await generateText({
        model,
        system: "You are a helpful agent that provides weather updates.",
        prompt,
        tools: {
          getWeather: tool({
            description: "Get the current weather for a given city.",
            inputSchema: z.object({ city: z.string() }),
            execute: async ({ city }) =>
              ctx.run("get weather", () => fetchWeather(city)),
          }),
        },
        stopWhen: [stepCountIs(5)],
        providerOptions: { openai: { parallelToolCalls: false } },
      });

      return text;
    },
  },
});
```

- **Vercel AI SDK**: Use Restate's `durableCalls` middleware to persist LLM responses automatically
- **Tool execution**: Make tool execution steps resilient with `ctx.run` and other Context actions
- **Flexibility**: Works with your existing deployment - Docker, Kubernetes, AWS Lambda, or any serverless platform
- **Integration**: From simple agents to complex multi-agent orchestration systems

### Built-in Observability

Track every step of your agent's execution with detailed traces and state inspection:

<Frame>
<img src="/img/tour/agents/weather-agent.png" alt="AI Agent Execution Trace" />
</Frame>

- **Complete execution timeline**: See every LLM call, tool execution, and state change
- **Debug failed agents**: Inspect exactly where and why agents failed
- **OpenTelemetry integration**: Export traces to Langfuse, DataDog, or custom systems

## Key AI Agent Patterns

### Stateful Conversational Agents

Maintain conversation history and context across multiple interactions using Virtual Objects:

```typescript
export default restate.object({
  name: "Chat",
  handlers: {
    message: async (ctx: restate.ObjectContext, req: { message: string }) => {
      const model = wrapLanguageModel({
        model: openai("gpt-4o"),
        middleware: durableCalls(ctx, { maxRetryAttempts: 3 }),
      });

      const messages =
        (await ctx.get<ModelMessage[]>("messages", superJson)) ?? [];
      messages.push({ role: "user", content: req.message });

      const res = await generateText({
        model,
        system: "You are a helpful assistant.",
        messages,
      });

      ctx.set("messages", [...messages, ...res.response.messages], superJson);
      return { answer: res.text };
    },
  },
});
```

### Human-in-the-Loop Workflows

Implement resilient approval workflows and human oversight without complex infrastructure:

```typescript
const approval = await ctx.awakeable<boolean>();
await ctx.run("request-approval", () => 
  sendApprovalRequest(approval.id, decision)
);
const decision = await approval.promise;
```

- **Durable waiting**: Waiting continues across crashes and restarts
- **Timeout handling**: Set crash-proof timeouts with automatic escalation paths
- **Cost efficiency**: No compute costs while waiting on serverless platforms

### Multi-Agent Orchestration

Coordinate specialized agents for complex tasks with reliable communication:

```typescript
const [eligibility, fraud, cost] = await Promise.all([
  ctx.serviceClient(eligibilityAgent).analyze(claim),
  ctx.serviceClient(fraudAgent).analyze(claim),
  ctx.serviceClient(costAgent).analyze(claim),
]);

const decision = await generateText({
  model,
  prompt: `Make decision based on: ${eligibility}, ${fraud}, ${cost}`,
});
```

### Advanced Agent Patterns

<CardGroup cols={3}>
    <Card title="Parallel Execution" icon="arrows-split-up-and-left" href="/tour/ai-agents#parallel-work">
        Speed up multi-step workflows with recoverable parallel tasks
    </Card>
    <Card title="Manual Control Loops" icon="code" href="/tour/ai-agents#advanced-patterns">
        Implement custom agent logic with full control over execution flow and tool calling
    </Card>
    <Card title="Error Handling" icon="triangle-exclamation" href="/tour/ai-agents#error-handling">
        Handle failing LLM call and tool errors with flexible logic and retry policies
    </Card>
    <Card title="Compensation Patterns" icon="arrow-rotate-left" href="/tour/ai-agents#advanced-patterns">
        Automatically undo previous actions when later steps fail with rollback/saga patterns
    </Card>
    <Card title="Interruptible Agents" icon="hand" href="https://github.com/igalshilman/agent47/tree/main/packages/agent">
        Build agents that can be paused, modified, and resumed during execution
    </Card>
    <Card title="Streaming Results" icon="water" href="https://github.com/igalshilman/agent47/tree/main/packages/pubsub">
        Stream intermediate results and progress updates in real-time
    </Card>
</CardGroup>

## When to Choose Restate

**âœ… Choose Restate when you need:**
- **Durable Execution**: Crash-safe LLM/tool calls and idempotent retries. Agents resume at the last successful step.
- **Journal Observability**:	Auto-captured journal of every step, retry, and message for easy debugging and auditing.
- **Human-in-the-loop & long waits**:	Suspend while waiting for user approval or slow jobs; pay for compute, not wall-clock time.
- **Stateful sessions / memory**: Virtual Objects keep multi-turn conversations and other state isolated and consistent.
- **Multi-agent orchestration**: Reliable RPC, queuing, and scheduling between agents running in separate processes.

<Info>
    Building AI agents with Restate? Join our community on [Discord](https://discord.com/invite/skW3AZ6uGd) or [Slack](https://join.slack.com/t/restatecommunity/shared_invite/zt-2v9gl005c-WBpr167o5XJZI1l7HWKImA) to share your use case and get help from other developers.
</Info>

## Getting Started

Ready to build resilient AI agents with Restate? Here are your next steps:

<CardGroup cols={3}>
  <Card title="Quickstart" icon="rocket" href="/installation">
    Set up Restate and run your first agent
  </Card>
  <Card title="Hands-on Tutorial" icon="pen" href="/tour/ai-agents">
    Build durable agents, chatbots, and multi-agent systems
  </Card>
  <Card title="Need help?" icon="thought-bubble">
    Discuss your AI agent use case on <strong>[Discord](https://discord.gg/skW3AZ6uGd)</strong> or <strong>[Slack](https://join.slack.com/t/restatecommunity/shared_invite/zt-2v9gl005c-WBpr167o5XJZI1l7HWKImA)</strong>.
  </Card>
</CardGroup>

## Examples

Explore AI agent patterns for common scenarios:

- **[Durable agent templates](/tour/ai-agents)** that recover from API failures and rate limits
- **[Insurance claims](/tour/ai-agents)**: Multi-agent analysis with human approval workflows and compensation patterns
- **[Chat sessions](/tour/ai-agents)**: Stateful conversational agents with persistent memory
- **[Code generation](https://github.com/igalshilman/agent47/tree/main)**: Interactive coding agents with interruption and streaming
- [Complete AI examples repository](https://github.com/restatedev/ai-examples/tree/main)

