---
title: "AI Agents"
description: "Quickly build fault-tolerant, observable, and long-running AI agents that support advanced interaction patterns"
icon: "robot"
---

Use Restate to make AI agents **resilient to failures** (let them recover back to where they left off), **scalable**, **observable**, and support **advanced workflow patterns** for multi-turn conversations with users, orchestrating other processes or agents, asking for human approval, or reacting to interruptions (new input).

Restate's stateful durable functions can be used both to add these properties to **existing AI Agent SDKs** (e.g., [Vercel AI SDK](...), [OpenAI Agent SDK](...), [Google ADK](...)) as well as to **implement custom workflows** with AI-augmented steps.

We'll cover the following topics:
* Durable execution
* Using Restate with other Agent SDKs
* Observability
* Human-in-the-loop, with timeouts and escalation
* Managing conversation history and other context 
* Multi-agent orchestration
* Advanced patterns and utilities


## Setting up our Agent project with Restate

A Restate AI application has two parts:
- **Restate Server**: Manages durable execution and routes requests to your agents
- **Agent Services**: Your AI logic using the Restate SDK for durability

agent template
start restate
register

We can now invoke our agent, and once the invocation has been sent, Restate will ensure the agent will keep retrying across failures.
 - invoke via curl or UI

_(Maybe) Bonus (collapsed): Invoke async, schedule invocation._


## Durable Execution: Recovering previous progress

AI agents are long-running functions or processes that reason with the help of LLMs and interact with the world using tools. To recover an agent's progress means recovering results of previous LLM- and tool calls.

Example: Doesn't use an SDK, only does an LLM call, a tool call, another LLM call.

> HIGHLIGHT: Compared to workflow engines, Restate's durable function model allows us to keep the agent as one long running function: We don't need to split out LLM calls and tool calls as activities, sparing us from moving context and other shared resources back and forth.

...


## Building an Agent Loop

Agent loop with Vercel or OpenAI SDK, possibly third tab is manual loop



## Observing and Debugging our Agent

One line description
A short video

_(maybe) bonus (collapsed): Setting up OTEL to export traces to another system (like Langfuse)_



## Human approvals

### Approving tool calls

Loop example and have some high risk tools that need approval


### Approval step in the workflow

This is not within the loop, but after an agent loop part as a separate explicit step

 - timeout, escalation, ...



## Multi-turn conversations & managing context




## Parallelizing Tasks & Sub-workflows

Parallel steps

Parallel sequences of steps: put work into separate functions.
Also gives you
 - simplify recovery (shorter replay)
 - shorten journal accumulation


## Multi-agent orchestration

Simple case be described shortly as a special case of subworkflows

Generally, use orchestrator (VO with context state) that kicks off agents for work


## Further reading: Advanced patterns

Mini description 
 - PubSub to send steps back for user to see
 - Streaming inference calls live to UI
 - Interruptibe agent (coding agent example from Igal/Stephan)


## >>>>>>>>>> ARCHIVE <<<<<<<<<<

### How It Works

Restate Server persists operations in a log. LLM calls and tool invocations made through the Restate context are logged once and cached on replay:

ANIMATION

### Integrating Restate with AI SDKs

To use durable execution, wrap expensive operations (LLM calls, tool invocations) in durable steps. Many AI SDKs support middleware for this.

Here's how to make an agent durable with the Vercel AI SDK:

```ts
async function simpleAgent(restate: restate.Context, prompt: string) {
  const model = wrapLanguageModel({
    model: openai("gpt-4o-2024-08-06", { structuredOutputs: true }),
    middleware: durableCalls(restate, { maxRetryAttempts: 3 }),
  });

  const result = await generateText({
    model,
    tools: {
      getWeather: tool({
        description: "Get the current weather for a given city.",
        parameters: z.object({ city: z.string() }),
        execute: async ({ city }) => {
          // call tool wrapped as Restate durable step
          return await restate.run("get weather", () => fetchWeather(city));
        }
      })
    },
    maxSteps: 5,
    maxRetries: 3,
    system: "You are a helpful agent.",
    messages: [{ role: "user", content: prompt }]
  });

  return result.text;

}
```

Serve the agent as a Restate service:

```ts
const agent = restate.service({
  name: "agent",
  handlers: {
    run: async (ctx: restate.Context, prompt: string) => {
      return simpleAgent(ctx, prompt);
    },
  },
  options: {
    journalRetention: { days: 1 },
    ...toolErrorAsTerminalError,
  },
});

restate.endpoint()
  .bind(agent)
  .listen(9080);
```

Start the server:

```bash
restate-server
```

## Observability

The Restate UI shows what's stored in the execution journal.


## Durable Tools

Tool execution can fail. Use the Restate Context to persist steps within your tool execution. This ensures that if a tool call fails, steps it already completed will not repeat on retry.

### Durable steps
To wrap non-deterministic operations (like API calls) in durable steps, use `ctx.run()`:

```typescript
const weatherTool = tool({
  description: "Get weather for a city",
  parameters: z.object({ city: z.string() }),
  execute: async ({ city }) => {
    // This API call won't repeat on replay
    return await ctx.run("fetch-weather", () => 
      fetch(`https://api.weather.com/v1/current?q=${city}`)
        .then(res => res.json())
    );
  }
});
```

### Human-in-the-Loop Steps

Some agent actions need human approval. Use awakeables to pause execution until a human responds:

```typescript
const dangerousTool = tool({
  description: "Do something dangerous",
  parameters: z.object({ task: z.string() }),
  execute: async ({ task }) => {
    const id, approvalPromise = await ctx.awakeable<boolean>()
    await restate_context.run("request-approval", () =>
      requestToolExecutionApproval(task, id)
    );
    const approved = await approvalPromise;

    if (!approved) {
      throw new Error("Tool execution not approved by human. Try another tool or ask for help.");
    }
  }
});
```

### Schedule Background Tasks

You can let tools schedule background tasks that either run immediately or at a later time:


```typescript
const followUpWithPatient = tool({
  description: "Schedule follow-up",
  parameters: z.object({ patientId: z.string(), topic: z.string() }),
  execute: async ({ patient, topic }) => {
      // Ask patient how the treatment is going 3 days later
      ctx.serviceClient(emailService).followUp(patient, topic, {delay: "3 days"});
  }
});
```

### Parallel Tool Execution

Run independent tools concurrently:

```typescript
const parallelToolsAgent = restate.service({
  name: "ParallelToolsAgent",
  handlers: {
    gatherComprehensiveData: async (ctx, request: { topic: string }) => {
      // Start all data gathering operations in parallel
      const [webResults, dbResults, apiResults] = await Promise.all([
        ctx.run("web-search", () => searchWeb({ query: request.topic })),
        ctx.run("database-search", () => queryDatabase({ 
          sql: `SELECT * FROM articles WHERE topic LIKE '%${request.topic}%'` 
        })),
        ctx.run("external-api", () => fetchFromExternalAPI({ 
          endpoint: "research", params: { topic: request.topic } 
        }))
      ]);
      
      // Process and combine results
      const combinedData = await ctx.run("combine-results", () =>
        generateText({
          model: openai("gpt-4o"),
          prompt: `Combine and synthesize these research results about ${request.topic}`,
          maxTokens: 4096
        })
      );
      
      return {
        synthesizedData: combinedData.text,
        totalSources: webResults.length + dbResults.length + apiResults.length
      };
    }
  }
});
```

Restate will take care of retries of each step, and finally will collect the results.

## Agent Context and State

Agents need to maintain conversation history and state. Virtual Objects provide isolated, consistent state management per agent session:

```typescript
// Keyed by session ID
const agent = restate.object({
    name: "Agent",
    handlers: {
        run: async (restate_ctx: restate.ObjectContext, message: string) => {
            // Load the session context
            const messages = (await restate_ctx.get<Message[]>("messages")) ?? [];
            messages.push({role: "user", content: message});

            const result = await runVercelAIAgent(restate_ctx, messages);

            // Store the session context
            messages.push({role: "assistant", content: result});
            restate_ctx.set("messages", messages);
            return result;
        },
    }
});
```
## Multi-Agent Orchestration

Complex tasks can be split across specialized agents. Call other agents from within tools:

**Request-Response**: Wait for another agent's result:

```typescript
tool({
    description: "Handoff to BlueSky agent for research.",
    parameters: z.object({ prompt: z.string() }),
    execute: async ({ prompt }) =>
        await restate_ctx.serviceClient(blueSkyAgent).run_agent(prompt),
});
```

**Fire-and-Forget**: Start agents without waiting for results:

```typescript
const parallelProcessingAgent = restate.service({
  name: "ParallelAgent",
  handlers: {
    processDocument: async (ctx, request: { documentId: string; userId: string }) => {
      // Start multiple agents working in parallel
      ctx.serviceSend(summaryAgent).generateSummary({ 
        documentId: request.documentId 
      });
      
      ctx.serviceSend(keywordAgent).extractKeywords({ 
        documentId: request.documentId 
      });
      
      ctx.serviceSend(sentimentAgent).analyzeSentiment({ 
        documentId: request.documentId 
      });
      
      // Continue with main processing - other agents work in background
      const mainProcessing = await ctx.run("main-processing", 
        () => processDocumentMain(request.documentId)
      );
      
      return { processedId: request.documentId, status: "processing" };
    }
  }
});
```

## Long-running Agents

Use Virtual Objects for agents that run continuously, checking for new tasks periodically:

```typescript
const backgroundAgent = restate.object({
  name: "BackgroundAgent",
  handlers: {
    start: async (ctx) => {
      while (await ctx.get<boolean>("active")) {
        const tasks = await ctx.run("check-tasks", () => checkForNewTasks());
        
        for (const task of tasks) {
          await ctx.run(`process-${task.id}`, () => processTask(task));
        }
        
        await ctx.timer(Duration.ofMinutes(5)); // Check every 5 minutes
      }
    },
    
    stop: async (ctx) => {
      ctx.set("active", false);
    }
  }
});
```

## Custom AI Workflows

You can build AI workflows directly with the Restate SDK instead of using agent frameworks. Common patterns:

<CardGroup>
    <Card title={"Chaining LLM Calls"} href={"/develop/ts/llm-chains"}/>
    <Card title={"Parallelizing Calls"} href={"/develop/ts/llm-chains"}/>
    <Card title={"Routing"} href={"/develop/ts/llm-chains"}/>
    <Card title={"Evaluator-optimizer"} href={"/develop/ts/llm-chains"}/>
</CardGroup>

## Summary

Restate provides these patterns for building resilient AI agents:

- **Durable Execution**: LLM calls and tool invocations are cached and don't repeat on retry
- **Human-in-the-Loop**: Use awakeables and timers for approval workflows
- **Persistent State**: Virtual Objects maintain conversation history across failures  
- **Multi-Agent**: Coordinate multiple specialized agents with reliable communication

These patterns handle the unique challenges of AI systems: expensive operations, non-deterministic execution, and long-running workflows.