---
title: "AI Agents"
description: "Build fault-tolerant, observable AI agents that recover from failures and support advanced interaction patterns."
icon: "robot"
---

import { GitHubLink } from '/snippets/blocks/github-link.mdx';

AI agents are long-running processes that combine LLMs with tools and external APIs to complete complex tasks. With Restate, you can build agents that are **resilient to failures**, **stateful across conversations**, and **observable** without managing complex retry logic or external state stores.

In this guide, you'll learn how to:
- Build durable AI agents that recover automatically from crashes and API failures
- Integrate with existing AI SDKs like Vercel AI SDK and OpenAI
- Observe and debug agent executions with detailed traces
- Implement resilient human-in-the-loop workflows with approvals and timeouts
- Manage conversation history and state across multi-turn interactions
- Orchestrate multiple agents working together on complex tasks

## Getting Started

A Restate AI application has two main components:
- **Restate Server**: The core engine that takes care of the orchestration and resiliency of your agents
- **Agent Services**: Your agent or AI workflow logic using the Restate SDK for durability

<img src="/img/tour/app_layout.svg" alt="Application Structure"/>

Restate works with how you already deploy your agents, whether that's in Docker, on Kubernetes, or via AWS Lambda. You don't need to run your agents in any special way.

Let's run an example locally to get a better feel for how it works.

### Run the example
[Install Restate](/develop/local_dev) and launch it:
```bash
restate-server
```

Get the example:
```bash
restate example typescript-ai-agents && cd typescript-ai-agents
npm install
```
<GitHubLink url="https://github.com/restatedev/ai-examples" />

Run the agent:
```bash
npm run dev
```

Then, tell Restate where your agent is running via the UI (`http://localhost:9070`) or CLI:
```bash
restate deployments register http://localhost:9080
```

To invoke the agent:
```bash
curl localhost:8080/WeatherAgent/run \
  --json '{"prompt": "What's the weather like in San Francisco?"}'
```

You should see the weather information printed in the terminal.

Let's have a look at what happened under the hood.

## Durable Execution

AI agents make multiple LLM calls and tool executions that can fail due to rate limits, network issues, or service outages.
Restate uses Durable Execution to make your agents withstand failures without losing progress.

The Restate SDK records the steps the agent executes in a log and replays them if the process crashes or is restarted:
<img src="/img/tour/durable_execution_microservices.gif" alt="Durable AI Agent Execution" />

### Implementing a Durable Agent
To implement a durable agent, you can use the Restate SDK in combination with existing AI frameworks like the Vercel AI SDK.

Here's the implementation of the durable weather agent you just invoked:

```typescript
const runWeatherAgent = async (ctx: restate.Context, prompt: string) => {
  const model = wrapLanguageModel({
    model: openai("gpt-4o-mini"),
    middleware: durableCalls(ctx, { maxRetryAttempts: 3 }),
  });

  const result = await generateText({
    model,
    tools: {
      getWeather: tool({
        description: "Get the current weather for a given city.",
        parameters: z.object({ city: z.string() }),
        execute: async ({ city }) =>
          ctx.run("get weather", () => fetchWeather(city)),
      }),
    },
    system: "You are a helpful agent.",
    messages: [{ role: "user", content: prompt }],
  });

  return result.text;
};

const weatherAgent = restate.service({
  name: "WeatherAgent",
  handlers: {
    run: runWeatherAgent,
  },
  options: { ...toolErrorAsTerminalError },
});

restate.endpoint().bind(weatherAgent).listen(9080);
```

The main difference compared to a standard Vercel AI SDK setup is the use of the Restate Context at key points throughout the agent logic.
Any action with the Context is automatically recorded by the Restate Server and survives failures.
We use this for:
1. **Persisting LLM responses**: We wrap the model with the `durableCalls(ctx)` middleware, so that every LLM response is saved in Restate Server and can be replayed during recovery. The middleware is provided via the package [`@restatedev/vercel-ai-middleware`](https://github.com/restatedev/vercel-ai-middleware).
2. **Resilient tool execution**: Tools can make steps durable by using Context actions. Their outcome will then be persisted for recovery and retried until they succeed.

The agent logic is called from a handler of a Restate service, here the `run` handler. Once deployed and registered, you can invoke the handler over HTTP at `localhost:8080/WeatherAgent/run`.

<Tip> Unlike workflow engines, Restate’s durable function model lets you implement the agent as one long-running function. You don’t need to split LLM calls and tool calls into separate activities, avoiding the overhead of passing context and state around. </Tip>

<Accordion title={"Try it out"}>
    Ask for weather in Denver:
    ```bash
    curl localhost:8080/weather-agent/run \
    --json '{"prompt": "What's the weather like in Denver?"}'
    ```

    In the invocation page, you can see each weather API call being executed durably. Try restarting the service during execution to see how it recovers seamlessly.
</Accordion>

### Resilient actions
The Restate Context provides durable execution primitives that you can use to make any action resilient to failures. Some of the most useful ones are:
- `ctx.run("name", () => asyncAction())`: Runs an action durably, retrying it until it succeeds (e.g. database interaction, API calls, non-deterministic actions).
- `ctx.sleep(ms)`: Sleep for a given time durably, surviving process restarts (e.g. timers and timeouts).
- `ctx.awakeable<T>()`: Create a recoverable promise that can be resolved externally (e.g. human-in-the-loop approvals as we will see later).
- `ctx.serviceClient(OtherService)`: Call another Restate service durably (e.g. sub-agents and microservices). Provide a delay parameter to schedule a task for later.

You can use these actions anywhere in your agent logic, so also outside tools, to build resilient AI workflows.

A few of these will be covered in more detail later in this tour.

## Observability and Debugging

Restate includes a UI for monitoring and debugging your agents. The Invocations tab shows all agent executions with detailed traces of every LLM call, tool execution, and state change.

Go to the UI at `http://localhost:9070/ui/invocations` and click on your invocation id to see the complete timeline:
<Frame>
<img src="/img/tour/ai-agents/agent-trace.png" alt="AI Agent Execution Trace" />
</Frame>

<Accordion title={"OpenTelemetry Integration"}>
    Restate supports OpenTelemetry for exporting traces to external systems like Langfuse, DataDog, or Jaeger:

    ```bash
    # Set environment variables for OTEL export
    export OTEL_EXPORTER_OTLP_ENDPOINT=https://your-langfuse-instance.com/api/public/ingestion
    export OTEL_EXPORTER_OTLP_HEADERS="Authorization=Bearer your-api-key"
    
    # Start Restate with OTEL enabled
    restate-server --otel-endpoint $OTEL_EXPORTER_OTLP_ENDPOINT
    ```

    This gives you AI agent traces alongside your existing observability stack.
</Accordion>


## Human-in-the-Loop Workflows

Many AI agents need human oversight for high-risk decisions or gathering additional input. Restate makes it easy to pause agent execution and wait for human input.

Here's an insurance claim agent that extracts claim data and asks the customer for more info if needed:

```typescript
const response = await generateText({
    model,
    prompt: `Extract claim data: ${prompt} and fill in missing fields by asking the customer.`,
    tools: {
        askMoreInfo: tool({
            description: "If the claim data is incomplete, ask the customer for additional information.",
            parameters: InsuranceClaimSchema,
            execute: async (params) => {
                const responsePromise = ctx.awakeable<string>();
                await ctx.run("email", () => emailCustomer(
                    "Your request is incomplete. Fill in the missing data: " + JSON.stringify(params),
                    responsePromise.id)
                )
                const response = await responsePromise.promise
                return `Additional information: ${response}`;
            }
        })
    },
    experimental_output: Output.object({schema: InsuranceClaimSchema})
});
```

To implement human approval steps, you can use Restate's awakeables. An awakeable is a promise that can be resolved externally via an API call by providing its ID.
When you create the awakeable, you get back an ID and a promise. You can send the ID to the human approver, and then wait for the promise to be resolved.

You can also use awakeables outside of tools, for example, to implement human approval steps in between agent iterations.

**Benefits with Restate:**
- If the agent crashes while waiting for human input, Restate continues waiting and recovers the promise on another process
- If the agent runs on function-as-a-service platforms, Restate suspends the function while its waiting, and resumes it later. You don't pay for the wait time.


<Accordion title={"Try it out"}>
    Start a weather request that needs approval:
    ```bash
    curl localhost:8080/weather-agent/chat \
      --json '{"prompt": "Get detailed 7-day forecast for 10 cities with satellite imagery"}'
    ```

    The agent will pause for approval. Provide it:
    ```bash
    curl localhost:8080/weather-agent/approve \
      --json '{"requestId": "req-123", "approved": true}'
    ```

    Watch in the UI how the workflow pauses and resumes after approval.
</Accordion>

<Accordion title={"Timeouts and Escalation"}>
    Add timeouts to human approval steps to prevent workflows from hanging indefinitely:

    ```typescript
    try {
      const decision = await ctx.promise<ApprovalDecision>("human-approval")
        .orTimeout({ hours: 24 });
      return decision;
    } catch (e) {
      if (e instanceof TimeoutError) {
        // Escalate to manager or auto-reject
        return { approved: false, reason: "Approval timeout - escalated" };
      }
      throw e;
    }
    ```
</Accordion>



## Multi-turn Conversations and State

AI agents often need to maintain conversation history and context across multiple interactions.

To implement stateful entities like chat sessions, or stateful agents, Restate provides Virtual Objects.

Each Virtual Object instance maintains isolated state and is identified by a unique key.

Here's an example of a Virtual Object that represents chat sessions:

```typescript
const chatSession = restate.object({
    name: "chat",
    handlers: {
        message: async (ctx: restate.ObjectContext<ChatState>, message: string) => {
                const model = wrapLanguageModel({
                    model: openai("gpt-4o", { structuredOutputs: true }),
                    middleware: durableCalls(ctx, { maxRetryAttempts: 3 }),
                });

                const messages = (await ctx.get("messages", superJson)) ?? [];

                messages.push({ role: "user", content: message } as CoreMessage);

                const res = await generateText({
                    model,
                    maxRetries: 0,
                    system: "You are a helpful assistant.",
                    messages,
                });

                ctx.set("messages", [...messages, ...res.response.messages], superJson);
                return res.text;
        },
        getMessages: restate.handlers.object.shared(
            async (ctx: restate.ObjectSharedContext<ChatState>) => {
                return await ctx.get("messages", superJson) ?? []
            }
        )
    },
});
```

Virtual Objects are ideal for implementing any entity with mutable state.
Restate ensures that your state is durable and consistent:
- Handlers either have read-write access (`ObjectContext`) or read-only access (`ObjectSharedContext`). Only one handler with write access can run at a time per object key (no concurrent/lost writes or race conditions). Handlers with read-only access can run concurrently to the write-access handlers.
- State changes are logged with Durable Execution: they survive failures and are consistent with code execution
- Different object keys can be processed in parallel, so you can scale horizontally without risking concurrency issues
- K/V state is stored permanently. It has no automatic expiry. Clear it via `ctx.clear()`.
- State is queryable via the UI:

<Frame>
<img src="/img/tour/ai-agents/conversation-state.png" alt="Conversation State Management" />
</Frame>

<Accordion title={"Try it out"}>
    Start a medical claim conversation with a specific patient ID:
    ```bash
    curl localhost:8080/medical-claim-conversation/patient-456/chat \
      --json '{"message": "Hi, I received a denial letter for my recent MRI scan. Can you help me understand why it was denied?"}'
    ```

    Continue the conversation - the agent remembers previous medical context:
    ```bash
    curl localhost:8080/medical-claim-conversation/patient-456/chat \
      --json '{"message": "The scan was ordered by my neurologist for chronic headaches that have been getting worse over the past 6 months"}'
    ```

    Get conversation history:
    ```bash
    curl localhost:8080/medical-claim-conversation/patient-456/getHistory
    ```

    The agent maintains medical context across all interactions, building a comprehensive understanding of the patient's healthcare journey and coverage needs.
</Accordion>



## Concurrent Tasks and Sub-workflows

Complex AI workflows often benefit from parallel execution, for example, running multiple agents simultaneously or breaking work into concurrent sub-tasks. This reduces overall execution time and allows specialized agents to work in parallel.

Here is an insurance claim agent that runs multiple analyses in parallel:

```typescript
const response = await generateText({
    model,
    prompt: `Analyze the claim ${JSON.stringify(claim)}.
        Decide whether to auto-approve or flag for human review.`,
    tools: {
      calculateMetrics: tool({
        description: "Calculate claim metrics.",
        parameters: InsuranceClaimSchema,
        execute: async (claim: InsuranceClaim) => {
          // Start analyses in parallel
          const eligibilityCheck = ctx.run("eligibility check", () =>
              doEligibilityCheck(claim),
          );
          const costReasonablenessScore = ctx.run("cost reasonableness", () =>
              compareToStandardRates(claim),
          );
          const fraudProbability = ctx.run("fraud check", () =>
              doFraudCheck(claim),
          );

          // Wait for all analyses to complete
          return await RestatePromise.allSettled([
            eligibilityCheck,
            costReasonablenessScore,
            fraudProbability,
          ]);
        },
      })
    }
});
```
Restate makes sure that all parallel tasks are retried and recovered until they succeed.

## Multi-Agent Orchestration


If each of the analysis tasks is complex, you can break them into separate sub-agents or workflows. Each sub-agent can be developed, deployed, and scaled independently:


Multi-agent systems coordinate specialized agents to solve complex problems. Restate provides reliable orchestration patterns where agents can communicate durably and maintain shared context.


### Sub-agents as tools

You can also dynamically offload specific tasks to sub-agents, by wrapping them as tools:

```typescript
export const claimAnalyzerAgent = restate.service({
  name: "medical-claim-analyzer",
  handlers: {
    run: async (ctx: restate.Context, claim: InsuranceClaim) => {
      const model = wrapLanguageModel({
        model: openai("gpt-4o-mini"),
        middleware: durableCalls(ctx),
      });

      const decision = await generateText({
        model,
        prompt: `Analyze the claim ${claim} and use your tools to decide whether to approve.`,
        system: "You are a claim decision engine.",
        tools: {
          analyzeEligibility: tool({
            description: "Analyze eligibility result.",
            parameters: InsuranceClaimSchema,
            execute: async (claim: InsuranceClaim) => ctx.serviceClient(eligibilityAgent).run(claim),
          }),
          analyzeCost: tool({
              description: "Compare cost to standard rates.",
              parameters: InsuranceClaimSchema,
              execute: async (claim: InsuranceClaim) => ctx.serviceClient(rateComparisonAgent).run(claim),
          }),
          analyzeFraud: tool({
              description: "Analyze probability of fraud.",
              parameters: InsuranceClaimSchema,
              execute: async (claim: InsuranceClaim) => ctx.serviceClient(fraudCheckAgent).run(claim),
          })
        },
      });

      await ctx.run("notify", () => emailCustomer(decision.text));

      return decision.text;
    },
  },
  options: { ...toolErrorAsTerminalError },
});
```

### Parallel Sub-Agents
Here's a medical claim evaluation system with multiple specialized agents:

```typescript
export const claimAnalyzerAgent = restate.service({
  name: "medical-claim-analyzer",
  handlers: {
    run: async (ctx: restate.Context, claim: InsuranceClaim) => {
      const [eligibility, rateComparison, fraudCheck] = await Promise.all([
        ctx.serviceClient(eligibilityAgent).run(claim),
        ctx.serviceClient(rateComparisonAgent).run(claim),
        ctx.serviceClient(fraudCheckAgent).run(claim),
      ]);

      const model = wrapLanguageModel({
        model: openai("gpt-4o-mini"),
        middleware: durableCalls(ctx),
      });

      const decision = await generateText({
        model,
        prompt: `Make final claim decision based on:
    Eligibility: ${eligibility}
Cost: ${rateComparison}
Fraud: ${fraudCheck}`,
        system: "You are a claim decision engine.",
      });

      await ctx.run("notify", () => emailCustomer(decision.text));

      return decision.text;
    },
  },
  options: { ...toolErrorAsTerminalError },
});
```

You can also run these agents in parallel inside one of the tools.



## Error handling

Many agent SDKs include retry behavior settings. Restate also does retries via Durable Execution, so let's look at how these interact.

### Retries of LLM calls

LLM calls are expensive. To protect you from infinite retry loops and high LLM costs, you can configure the retry behavior of both Restate and the AI SDK you are using.

For the Vercel AI SDK, you can set `maxRetries` on `generateText` calls to retry LLM calls that fail due to rate limits or transient errors (defaults to 2).
After exhausting the retries, the agent will throw an error and fail.
Restate will then retry the invocation with exponential back-off to handle longer downtimes, faulty processes, or network communication issues.

To limit the number of retries done by Restate, you can set the `maxRetryAttempts` parameter on the `durableCalls` middleware:

```typescript
const model = wrapLanguageModel({
  model: openai("gpt-4o-mini"),
  middleware: durableCalls(ctx, { maxRetryAttempts: 3 }),
});
```

For each retry issued by Restate, the Vercel AI SDK will retry the LLM call up to `maxRetries` times.
So with `maxRetryAttempts: 3` and `maxRetries: 2`, the LLM call will be attempted up to 6 times (3 Restate retries * 2 Vercel AI SDK attempts).


After Restate's retries are exhausted, the invocation will fail with a `TerminalError`, which is a Restate error type that indicates the failure is permanent and should not be retried anymore.
You can catch and handle terminal errors in your agent logic if needed (see below).


### Tool execution errors

The AI SDK wraps tool errors with an `ToolExecutionError`.
By default, Restate would infinitely retry this. this will unwrap any TerminalError's wrapped in a ToolExecutionError

toolErrorAsTerminalError


### Implementing rollback
Retries from Restate vs LLM vs .

just keep a list of compensations that you run on terminal error

## Advanced patterns
- Long-running background agents
- PubSub to send steps back for user to see
- Streaming inference calls live to UI
- Interruptibe agent (coding agent example from Igal/Stephan)

## Summary

Restate transforms AI agent development by providing:

- **Durable Execution**: Automatic recovery from failures without losing progress
- **State Management**: Persistent conversation history and context
- **Simple Integration**: Works with OpenAI API and other LLM providers
- **Human-in-the-Loop**: Seamless approval workflows with timeouts  
- **Multi-Agent Coordination**: Reliable orchestration of specialized agents
- **Advanced Patterns**: Real-time progress updates, interruptions, and long-running workflows

Build resilient, observable AI agents that handle real-world complexity without the typical infrastructure overhead.
