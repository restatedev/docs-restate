---
title: "Durable Steps"
description: "Persist results of operations."
icon: "list-check"
---

Restate uses an execution log to replay operations after failures and suspensions. Non-deterministic operations (database calls, HTTP requests, UUID generation) must be wrapped to ensure deterministic replay.

## Run 

Use `ctx.run` to safely wrap any non-deterministic operation, like HTTP calls or database responses, and have Restate store its result in the execution log.

```python {"CODE_LOAD::python/src/develop/journaling_results.py#side_effect"} 
async def call_llm(prompt: str) -> str:
    # ... implement ...
    return "llm response"

# specify the (async) function to call and its arguments
result = await ctx.run_typed("LLM call", call_llm, prompt="What is the weather?")

# or use a lambda to capture a single value
my_number = await ctx.run_typed("generate number", lambda: random.randint(0, 10))
```

Note that inside `ctx.run`, you cannot use the Restate context (e.g., `ctx.get`, `ctx.sleep`, or nested `ctx.run`).

<AccordionGroup>

  <Accordion title="Serialization">
      By default, the SDK serializes the journal entry with the [`json`](https://docs.python.org/3/library/json.html#) library.
      Alternatively, you can specify a [Pydantic model](/develop/python/serialization#pydantic) or [custom serializer](/develop/python/serialization#custom-serialization).
  </Accordion>

  <Accordion title="Error handling and retry policies">

  Failures in `ctx.run` are treated the same as any other handler error. Restate will retry it unless configured otherwise or unless a [`TerminalError`](/develop/python/error-handling) is thrown.

  You can customize how `ctx.run` retries via:

```py {"CODE_LOAD::python/src/develop/retries.py#here"} 
try:
    retry_opts = restate.RunOptions(
        max_attempts=10, max_retry_duration=timedelta(seconds=30)
    )
    await ctx.run_typed("write", write_to_other_system, retry_opts)
except TerminalError as err:
    # Handle the terminal error after retries exhausted
    # For example, undo previous actions (see sagas guide) and
    # propagate the error back to the caller
    raise err
```

  * You can limit retries by time or count
  * When the policy is exhausted, a `TerminalError` is thrown
  * See the [Error Handling Guide](/guides/error-handling) and the [Sagas Guide](/guides/sagas) for patterns like compensation

  </Accordion>
  <Accordion title="Increasing timeouts">
    If Restate doesn't receive new journal entries from a service for more than one minute (by default), it will automatically abort the invocation and retry it.

    However, some business logic can take longer to complete—for example, an LLM call that takes up to 3 minutes to respond.

    In such cases, you can adjust the service’s [abort timeout and inactivity timeout](/operate/configuration/services) settings to accommodate longer execution times.

    For more information, see the [error handling guide](/guides/error-handling).
  </Accordion>

</AccordionGroup>

## Deterministic randoms

When you do non-deterministic operations, like generating UUIDs or random numbers, you must ensure that the results are deterministic on replay.

### UUIDs

To generate stable UUIDs for things like idempotency keys:

```python {"CODE_LOAD::python/src/develop/journaling_results.py#uuid"} 
my_uuid = await ctx.run_typed("generate UUID", lambda: str(uuid.uuid4()))
```

### Random numbers

To generate a deterministic integer between `0` and `10`:


```python {"CODE_LOAD::python/src/develop/journaling_results.py#random_nb"} 
import random
import uuid

from restate import Service, Context
from datetime import timedelta
from restate.exceptions import TerminalError
import restate

my_service = Service("MyService")


def send_verification():
    pass

def fetch_user_data(user_id: int) -> dict:
    # Simulate fetching user data
    return {"user_id": user_id, "name": "John Doe"}

def fetch_order_history(user_id: int) -> list:
    # Simulate fetching order history
    return [{"order_id": 1, "user_id": user_id, "item": "Book"}, {"order_id": 2, "user_id": user_id, "item": "Pen"}]

analytics_service = Service("AnalyticsService")

@analytics_service.handler()
async def calculate_metrics(ctx: Context, user_id: int) -> dict:
    # Simulate calculating metrics
    return {"user_id": user_id, "metrics": {"purchases": 5, "visits": 10}}


@my_service.handler()
async def my_handler(ctx: Context, arg):
    async def call_llm(prompt: str) -> str:
        # ... implement ...
        return "llm response"

    # specify the (async) function to call and its arguments
    result = await ctx.run_typed("LLM call", call_llm, prompt="What is the weather?")

    # or use a lambda to capture a single value
    my_number = await ctx.run_typed("generate number", lambda: random.randint(0, 10))

    my_uuid = await ctx.run_typed("generate UUID", lambda: str(uuid.uuid4()))

    # Start operations concurrently
    call1 = ctx.run_typed("fetch_user", fetch_user_data, user_id=123)
    call2 = ctx.run_typed("fetch_orders", fetch_order_history, user_id=123)
    call3 = ctx.service_call(calculate_metrics, arg=123)

    # Now wait for results as needed
    user = await call1
    orders = await call2
    metrics = await call3

    claude = ctx.service_call(claude_sonnet, arg=f"What is the weather?")
    openai = ctx.service_call(open_ai, arg=f"What is the weather?")

    results_done = await restate.gather(claude, openai)
    results = [await result for result in results_done]

    _, confirmation_future = ctx.awakeable(type_hint=str)
    match await restate.select(
        confirmation=confirmation_future, timeout=ctx.sleep(timedelta(days=1))
    ):
        case ["confirmation", "ok"]:
            return "success!"
        case ["confirmation", "deny"]:
            raise TerminalError("Confirmation was denied!")
        case ["timeout", _]:
            raise TerminalError("Verification timer expired!")
    return None


@my_service.handler()
async def my_other_handler(ctx: Context, arg):
    async def call_llm(prompt: str, model: str) -> str:
        # ... implement ...
        return "llm response"
    call1 = ctx.run_typed("LLM call", call_llm, prompt="What is the weather?", model="gpt-4")
    call2 = ctx.run_typed("LLM call", call_llm, prompt="What is the weather?", model="gpt-3.5-turbo")
    async for future in restate.as_completed(call1, call2):
        # do something with the completed future
        print(await future)


    claude = ctx.service_call(claude_sonnet, arg=f"What is the weather?")
    openai = ctx.service_call(open_ai, arg=f"What is the weather?")

    pending, done = await restate.wait_completed(claude, openai)

    # collect the completed greetings
    greetings = [await f for f in done]

    # cancel the pending calls
    for f in pending:
        await f.cancel_invocation()

@my_service.handler()
async def claude_sonnet(ctx: Context, req: str) -> str:
    return f"Bonjour {req.content[13:]}!"

@my_service.handler()
async def open_ai(ctx: Context, req: str) -> str:
    return f"Hello {req.content[13:]}!"
```
